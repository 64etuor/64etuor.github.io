<!DOCTYPE html> <html lang="en"><head>
<title>앤드류 응의 머신러닝(7-1): 과적합 문제</title>
<base href="../..">
<meta name="pathname" content="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html">
<meta name="description" content="온라인 강의 플랫폼 코세라의 창립자인 앤드류 응 (Andrew Ng) 교수는 인공지능 업계의 거장입니다. 그가 스탠퍼드 대학에서 머신 러닝 입문자에게 한 강의를 그대로 코세라 온라인 강의 (Coursera.org)에서 무료로 배울 수 있습니다. 이 강의는 머신러닝 입문자들의 필수코스입니다. 인공지능과 머신러닝을 혼자 공부하면서 자연스럽게 만나게 되는 강의입">
<meta property="og:title" content="앤드류 응의 머신러닝(7-1): 과적합 문제">
<meta property="og:description" content="온라인 강의 플랫폼 코세라의 창립자인 앤드류 응 (Andrew Ng) 교수는 인공지능 업계의 거장입니다. 그가 스탠퍼드 대학에서 머신 러닝 입문자에게 한 강의를 그대로 코세라 온라인 강의 (Coursera.org)에서 무료로 배울 수 있습니다. 이 강의는 머신러닝 입문자들의 필수코스입니다. 인공지능과 머신러닝을 혼자 공부하면서 자연스럽게 만나게 되는 강의입">
<meta property="og:type" content="website">
<meta property="og:url" content="./https://64etuor.github.io/600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html">
<meta property="og:image" content="http://t1.daumcdn.net/brunch/service/user/17Xk/image/F8qshn_Lwb7KFeleDZ-RGWssLVE.png">
<meta name="author" content="[[라인하트]]"></head><body class="publish css-settings-manager show-inline-title show-ribbon is-focused"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="parsed-feature-container" style="display: contents;"><link itemprop="include" href="site-lib/html/custom-head-content-content.html"></div><meta charset="UTF-8"><meta property="og:site_name" content="Obsidian"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0"><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="./https://64etuor.github.io/site-lib/rss.xml"><script async="" id="webpage-script" src="site-lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-wasm-script" src="site-lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="site-lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="site-lib/media/favicon.png"><link rel="stylesheet" href="site-lib/styles/obsidian.css"><link rel="stylesheet" href="site-lib/styles/theme.css"><link rel="preload" href="site-lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="site-lib/styles/supported-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/supported-plugins.css"></noscript><link rel="preload" href="site-lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/main-styles.css"></noscript><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-vertical-spacing:1.3em;--sidebar-margin:12px}:root{background-color:#202124}.sidebar{height:100%;font-size:14px;z-index:10;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));position:relative;overflow:hidden;overflow:clip;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}#left-sidebar{left:0}#right-sidebar{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}.sidebar.floating{position:absolute}.sidebar .leaf-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .leaf-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}#left-sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}#right-sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar #left-sidebar-content,.sidebar #right-sidebar-content{contain:none!important;container-type:normal!important;animation:none!important}.sidebar:has(.leaf-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:calc(2.3em + 2 * var(--sidebar-margin));width:var(--sidebar-width);padding:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}#left-sidebar .sidebar-topbar{left:0;flex-direction:row;border-top-right-radius:var(--radius-l)}#right-sidebar .sidebar-topbar{right:0;flex-direction:row-reverse;border-top-left-radius:var(--radius-l)}#left-sidebar .topbar-content{margin-right:calc(2.3em + var(--sidebar-margin));flex-direction:row}#right-sidebar .topbar-content{margin-left:calc(2.3em + var(--sidebar-margin));flex-direction:row-reverse}.topbar-content{overflow:hidden visible;overflow:clip visible;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:2px!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}#left-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}#right-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.feature-title{margin-left:1px;text-transform:uppercase;letter-spacing:.06em;margin-top:.75em;margin-bottom:.75em}.feature-header{display:flex;align-items:center;padding-top:0;font-size:1em;padding-left:0}body.floating-sidebars .sidebar{position:absolute}body{transition:background-color var(--color-fade-speed) ease-in-out}#navbar:not(:empty){display:flex;align-items:center;justify-content:space-between;padding:.5em 1em;width:100%}#main{display:flex;flex-direction:column;height:100%;width:100%;align-items:stretch;justify-content:center}#main-horizontal{display:flex;flex-direction:row;flex-grow:1;width:100%;align-items:stretch;justify-content:center}#center-content{flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0!important;transition:opacity .2s ease-in-out;pointer-events:none}#center-content>.obsidian-document{padding-left:2em;padding-right:1em;margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}body #center-content>.obsidian-document>.markdown-preview-sizer{padding-bottom:80vh;width:100%;max-width:var(--line-width);flex-basis:var(--line-width);transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document>div{width:100%!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document:not([data-type=markdown]).embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}#center-content>.obsidian-document:not([data-type=markdown]).embed>*{max-width:100%;max-height:100%;object-fit:contain}:not(h1,h2,h3,h4,h5,h6,li):has(> :is(.math,table)){overflow-x:auto!important}#center-content>.obsidian-document:not([data-type=markdown]){overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.obsidian-document[data-type=attachment]{display:flex;flex-direction:column;align-items:center;justify-content:center;height:100%;width:100%}.obsidian-document[data-type=attachment]>*{outline:0;border:none;box-shadow:none}.obsidian-document[data-type=attachment] :is(img){max-width:90%;max-height:90%;object-fit:contain}.obsidian-document[data-type=attachment]>:is(audio){width:100%;max-width:min(90%,var(--line-width))}.obsidian-document[data-type=attachment]>:is(embed,iframe,video){width:100%;height:100%;max-width:100%;max-height:100%;object-fit:contain}.canvas-wrapper>:is(.header,.footer){z-index:100;position:absolute;display:flex;justify-content:center;flex-direction:column;width:100%;align-items:center}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){let e=document.querySelectorAll("link[itemprop='include']");for(const t of e){let e=t.getAttribute("href");try{let o="";if(e.startsWith("https:")||e.startsWith("http:")||"file:"!=window.location.protocol){const n=await fetch(e);if(!n.ok){console.log("Could not include file: "+e),t?.remove();continue}o=await n.text()}else{const t=document.getElementById(btoa(encodeURI(e)));if(t){const e=JSON.parse(decodeURI(atob(t.getAttribute("value")??"")));o=e?.data??""}}let n=document.createRange().createContextualFragment(o);t.before(n),t.remove(),console.log("Included text: "+o),console.log("Included file: "+e)}catch(o){t?.remove(),console.log("Could not include file: "+e,o);continue}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script")));!function e(n){let l=o[n],c=n+1;l?(l&&"true"!=l.getAttribute("loaded")||n<o.length&&e(c),n<o.length&&l.addEventListener("load",(()=>e(c)))):n<o.length?e(c):t()}(0)}</script><div id="main"><div id="navbar"></div><div id="main-horizontal"><div id="left-content" class="leaf" style="--sidebar-width: var(--sidebar-width-left);"><div id="left-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><div id="search-container"><div id="search-wrapper"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div aria-label="Clear search" id="search-clear-button"></div></div></div></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="left-sidebar-content" class="leaf-content"><link itemprop="include" href="site-lib/html/file-tree-content.html"></div></div><script defer="">let ls = document.querySelector("#left-sidebar"); ls.classList.toggle("is-collapsed", window.innerWidth < 768); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div></div><div id="center-content" class="leaf"><div class="obsidian-document markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings allow-fold-lists show-indentation-guide show-properties" data-type="markdown"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;font-size-adjust:none;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-mfrac{display:inline-block;text-align:left}mjx-frac{display:inline-block;vertical-align:.17em;padding:0 .22em}mjx-frac[type="d"]{vertical-align:.04em}mjx-frac[delims]{padding:0 .1em}mjx-frac[atop]{padding:0 .12em}mjx-frac[atop][delims]{padding:0}mjx-dtable{display:inline-table;width:100%}mjx-dtable>*{font-size:2000%}mjx-dbox{display:block;font-size:5%}mjx-num{display:block;text-align:center}mjx-den{display:block;text-align:center}mjx-mfrac[bevelled]>mjx-num{display:inline-block}mjx-mfrac[bevelled]>mjx-den{display:inline-block}mjx-den[align=right],mjx-num[align=right]{text-align:right}mjx-den[align=left],mjx-num[align=left]{text-align:left}mjx-nstrut{display:inline-block;height:.054em;width:0;vertical-align:-.054em}mjx-nstrut[type="d"]{height:.217em;vertical-align:-.217em}mjx-dstrut{display:inline-block;height:.505em;width:0}mjx-dstrut[type="d"]{height:.726em}mjx-line{display:block;box-sizing:border-box;min-height:1px;height:.06em;border-top:.06em solid;margin:.06em -.1em;overflow:hidden}mjx-line[type="d"]{margin:.18em -.1em}mjx-mrow{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-mspace{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("site-lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("site-lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("site-lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("site-lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("site-lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("site-lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("site-lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("site-lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("site-lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("site-lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("site-lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("site-lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("site-lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("site-lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("site-lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("site-lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("site-lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("site-lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("site-lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("site-lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("site-lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("site-lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D443.TEX-I::before{padding:.683em .751em 0 0;content:"P"}mjx-c.mjx-c1D45F.TEX-I::before{padding:.442em .451em .011em 0;content:"r"}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c1D450.TEX-I::before{padding:.442em .433em .011em 0;content:"c"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c1D460.TEX-I::before{padding:.442em .469em .01em 0;content:"s"}mjx-c.mjx-c1D45C.TEX-I::before{padding:.441em .485em .011em 0;content:"o"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c1D439.TEX-I::before{padding:.68em .749em 0 0;content:"F"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c1D445.TEX-I::before{padding:.683em .759em .021em 0;content:"R"}mjx-c.mjx-c1D44E.TEX-I::before{padding:.441em .529em .01em 0;content:"a"}mjx-c.mjx-c1D459.TEX-I::before{padding:.694em .298em .011em 0;content:"l"}mjx-c.mjx-c1D441.TEX-I::before{padding:.683em .888em 0 0;content:"N"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c1D446.TEX-I::before{padding:.705em .645em .022em 0;content:"S"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c2217::before{padding:.465em .5em 0 0;content:"∗"}mjx-c.mjx-c3A::before{padding:.43em .278em 0 0;content:":"}mjx-c.mjx-c1D454.TEX-I::before{padding:.442em .477em .205em 0;content:"g"}mjx-c.mjx-c1D461.TEX-I::before{padding:.626em .361em .011em 0;content:"t"}mjx-c.mjx-c1D463.TEX-I::before{padding:.443em .485em .011em 0;content:"v"}mjx-c.mjx-c2C::before{padding:.121em .278em .194em 0;content:","}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c1D45D.TEX-I::before{padding:.442em .503em .194em 0;content:"p"}mjx-c.mjx-c1D453.TEX-I::before{padding:.705em .55em .205em 0;content:"f"}mjx-c.mjx-c1D466.TEX-I::before{padding:.442em .49em .205em 0;content:"y"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}</style><pre class="frontmatter language-yaml" style="display: none;" tabindex="0"><code class="language-yaml is-loaded"><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token string">"앤드류 응의 머신러닝(7-1): 과적합 문제"</span>
<span class="token key atrule">source</span><span class="token punctuation">:</span> <span class="token string">"https://brunch.co.kr/@linecard/483"</span>
<span class="token key atrule">author</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token string">"[[라인하트]]"</span>
<span class="token key atrule">published</span><span class="token punctuation">:</span> <span class="token datetime number">2020-10-21</span>
<span class="token key atrule">created</span><span class="token punctuation">:</span> <span class="token datetime number">2025-07-02</span>
<span class="token key atrule">description</span><span class="token punctuation">:</span> <span class="token string">"온라인 강의 플랫폼 코세라의 창립자인 앤드류 응 (Andrew Ng) 교수는 인공지능 업계의 거장입니다. 그가 스탠퍼드 대학에서 머신 러닝 입문자에게 한 강의를 그대로 코세라 온라인 강의 (Coursera.org)에서 무료로 배울 수 있습니다. 이 강의는 머신러닝 입문자들의 필수코스입니다. 인공지능과 머신러닝을 혼자 공부하면서 자연스럽게 만나게 되는 강의입"</span>
<span class="token key atrule">tags</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token string">"clippings"</span></code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre><div class="markdown-preview-sizer markdown-preview-section"><div class="header"><h1 class="page-title heading inline-title" id="앤드류_응의_머신러닝(7-1)_과적합_문제_0">앤드류 응의 머신러닝(7-1): 과적합 문제</h1><div class="data-bar"></div></div><div class="markdown-preview-pusher" style="width: 1px; height: 0.1px; margin-bottom: 0px;"></div><div class="el-p"><p dir="auto"><a data-tooltip-position="top" aria-label="https://brunch.co.kr/" rel="noopener nofollow" class="external-link is-unresolved" title="brunch" href="https://brunch.co.kr/" target="_self">브런치 스토리</a></p></div><div class="el-p"><p dir="auto">매거진 <a data-tooltip-position="top" aria-label="https://brunch.co.kr/magazine/ai-bigdata" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/magazine/ai-bigdata" target="_self">데이터 사이언티스트가 되자</a></p></div><div class="el-p"><p dir="auto"><a data-tooltip-position="top" aria-label="https://brunch.co.kr/@linecard/#likeit" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/@linecard/#likeit" target="_self">라이킷 10</a> <a data-tooltip-position="top" aria-label="https://brunch.co.kr/@linecard/#comments" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/@linecard/#comments" target="_self">댓글</a> 공유 <strong>작가의 글을 SNS에 공유해보세요</strong></p></div><div class="el-p"><p dir="auto">by <a data-tooltip-position="top" aria-label="https://brunch.co.kr/@linecard" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/@linecard" target="_self">라인하트</a></p></div><div class="el-p"><p dir="auto">온라인 강의 플랫폼 코세라의 창립자인 앤드류 응 (Andrew Ng) 교수는 인공지능 업계의 거장입니다. 그가 스탠퍼드 대학에서 머신 러닝 입문자에게 한 강의를 그대로 코세라 온라인 강의 (Coursera.org)에서 무료로 배울 수 있습니다. 이 강의는 머신러닝 입문자들의 필수코스입니다. 인공지능과 머신러닝을 혼자 공부하면서 자연스럽게 만나게 되는 강의입니다.</p></div><div class="el-h2"><h2 data-heading="Regularization" dir="auto" class="heading" id="Regularization_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Regularization</h2></div><div class="el-h2"><h2 data-heading="정규화" dir="auto" class="heading" id="정규화_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>정규화</h2></div><div class="el-h2"><h2 data-heading="Solving the Problem of Overfitting" dir="auto" class="heading" id="Solving_the_Problem_of_Overfitting_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Solving the Problem of Overfitting</h2></div><div class="el-h2"><h2 data-heading="(과적합 문제 해결하기)" dir="auto" class="heading" id="(과적합_문제_해결하기)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>(과적합 문제 해결하기)</h2></div><div class="el-h3"><h3 data-heading="The Problem of Overfitting (과적합 문제)" dir="auto" class="heading" id="The_Problem_of_Overfitting_(과적합_문제)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>The Problem of Overfitting (과적합 문제)</h3></div><div class="el-p"><p dir="auto">By now, you've seen a couple different learning algorithms, linear regression and logistic regression. They work well for many problems, but when you apply them to certain machine learning applications, they can run into a problem called overfitting that can cause them to perform very poorly. What I'd like to do in this video is explain to you what is this overfitting problem, and in the next few videos after this, we'll talk about a technique called regularization, that will allow us to ameliorate or to reduce this overfitting problem and get these learning algorithms to maybe work much better. So what is overfitting?</p></div><div class="el-p"><p dir="auto">지금까지 몇 종류의 학습 알고리즘을 배웠습니다. 선형 회귀와 로지스틱 회귀는 많은 머신 러닝 문제들에 적용할 수 있지만 과적합 문제를 일으킬 수 있습니다. 과적합 문제는 알고리즘의 성능에 좋지 않은 영향을 미칩니다. 이번 강의에서 과적합의 개념을 다루고 다음 강의에서 정규화를 다룹니다. <strong>정규화는 과적합 문제를 개선하여 학습 알고리즘의 성능을 향상합니다.</strong> 그렇다면 과적합이란 무엇일까요?</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 10.57.15 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/F8qshn_Lwb7KFeleDZ-RGWssLVE.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">Let's keep using our running example of predicting housing prices with linear regression where we want to predict the price as a function of the size of the house.</p></div><div class="el-p"><p dir="auto">여기 선형 회귀에서 주택 가격을 예측하는 예제가 있습니다. 주택 크기에 대해 주택 가격을 예측하는 함수입니다.</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 10.58.57 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/NCjSKYvLSsINxi6AFDEuVBypp7s.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">One thing we could do is fit a linear function to this data, and if we do that, maybe we get that sort of straight line fit to the data. But this isn't a very good model. Looking at the data, it seems pretty clear that as the size of the housing increases, the housing prices plateau, or kind of flattens out as we move to the right and so this algorithm does not fit the training and we call this problem underfitting, and another term for this is that this algorithm has high bias. Both of these roughly mean that it's just not even fitting the training data very well. The term is kind of a historical or technical one, but the idea is that if a fitting a straight line to the data, then, it's as if the algorithm has a very strong preconception, or a very strong bias that housing prices are going to vary linearly with their size and despite the data to the contrary. Despite the evidence of the contrary is preconceptions still are bias, still closes it to fit a straight line and this ends up being a poor fit to the data.</p></div><div class="el-p"><p dir="auto">데이터에 적합한 선형 함수를 그립니다. 왼쪽 그림은 1차 함수이므로 데이터에 적합한 직선을 그립니다. 이 모델은 좋은 모델은 아닌 것 같습니다. 데이터는 집의 크기가 늘어나면 집값이 증가하지만, 어느 정도가 지나면 집값의 평탄해집니다. <strong>알고리즘이 학습 데이터 셋에 적합하지 않습니다. 이것을 과소 적합 (Underfit) 또는 높은 편향성(High Bias)이라고 합니다.</strong> 두 용어는 가설 함수 모델이 데이터에 적합하지 않다는 의미입니다. 좀 오랜 전통의 전문 용어입니다. <strong>주택 크기와 주택 가격에 대한 데이터 분포와 상관없이 가설은 단순히 주택 크기에 따라 선형적으로 증가하기 때문에 알고리즘은 강한 선입견(Strong preconception)과 강한 편향(Stron Bias)이 있습니다</strong>. 데이터가 알고리즘의 예측과 다른 증거에도 불구하고, 데이터에 직선을 맞추려다 보니 편향(Bias)이 발생하고 결국 형편없는 결과가 나타납니다.</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.08.11 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/ps48IH4yEPu7jyqhrvZu39bh9m4.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">Now, in the middle, we could fit a quadratic functions enter and, with this data set, we fit the quadratic function, maybe, we get that kind of curve and, that works pretty well. And, at the other extreme, would be if we were to fit, say a fourth other polynomial to the data. So, here we have five parameters, theta zero through theta four, and, with that, we can actually fill a curve that process through all five of our training examples. You might get a curve that looks like this. That, on the one hand, seems to do a very good job fitting the training set and, that is processed through all of my data, at least. But, this is still a very wiggly curve, right? So, it's going up and down all over the place, and, we don't actually think that's such a good model for predicting housing prices. So, this problem we call overfitting, and, another term for this is that this algorithm has high variance.The term high variance is another historical or technical one. But, the intuition is that, if we're fitting such a high order polynomial, then, the hypothesis can fit, you know, it's almost as if it can fit almost any function and this face of possible hypothesis is just too large, it's too variable. And we don't have enough data to constrain it to give us a good hypothesis so that's called overfitting.</p></div><div class="el-p"><p dir="auto">중간 그림의 가설은 2차 함수이고 데이터에 적합한 곡선을 그립니다. 이건 꽤 좋습니다. 그리고, 오른쪽 그림은 극단적인 예제입니다. 가설은 4차 함수이고 데이터에 적합한 불규칙 곡선입니다. θ0에서 θ 5까지 5개의 파라미터를 활용해 5개의 데이터에 완전히 적합한 선을 만들 수 있습니다. 알고리즘은 학습 데이터 셋에 잘 맞고 성능도 좋습니다. 하지만, <strong>곡선은 엄청나게 꼬여 있어 보기 좋지 않기 때문에 곡선이 주택 가격을 제대로 예측하지 못할 것입니다. 이것을 과적합 (Overfit) 또는 높은 분산(High Variance)이 있다고 합니다.</strong> 높은 분산(High Variance) 용어도 오랜 전통의 전문 용어입니다. <strong>고차 다항식으로 이루어진 가설은 어떤 데이터에도 완벽히 맞출 수 있습니다. 큰 변동성을 가진 고차 다항식 가설을 제한할 수 있는 충분한 데이터가 없을 때 과적합이 발생합니다.</strong></p></div><div class="el-p"><p dir="auto">And in the middle, there isn't really a name but I'm just going to write, you know, just right. Where a second degree polynomial, quadratic function seems to be just right for fitting this data.</p></div><div class="el-p"><p dir="auto">중간의 그림은 특별히 이름이 없지만, 데이터에 적합(Just right)하다고 합니다. 데이터에 2차 함수의 곡선이 적합합니다.</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.22.17 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/3FJVbCipkvtlo0UAv1cJ9onanz8.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">To recap a bit the problem of over fitting comes when if we have too many features, then to learn hypothesis may fit the training set very well. So, your cost function may actually be very close to zero or may be even zero exactly, but you may then end up with a curve like this that, you know tries too hard to fit the training set, so that it even fails to generalize to new examples and fails to predict prices on new examples as well, and here the term generalized refers to how well a hypothesis applies even to new examples. That is to data to houses that it has not seen in the training set.</p></div><div class="el-p"><p dir="auto">정리하자면, <strong>과적합(Overfit) 문제은 피처가 너무 많아서 가설이 학습 데이터 셋에 과적합할 때 발생합니다. 학습 데이터 셋에 대한 비용 함수는 거의 0 이거나 0에 가까운 값이지만 엄청 복잡한 곡선을 그립니다.</strong> 따라서, 학습 데이터 셋에 완벽히 적합하지만 새로운 학습 예제를 제대로 예측하지 못합니다. <strong>일반화(Generalized)는 가설이 새로운 데이터에 얼마나 잘 맞는 지를 의미합니다.</strong> 여기서 새로운 데이터는 학습 데이터 셋에 없는 새로운 주택 크기와 주택 가격에 대한 데이터입니다.</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.31.28 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/JUhADfgJ5OUQtXiQBAycmMPy9j4.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">On this slide, we looked at over fitting for the case of linear regression. A similar thing can apply to logistic regression as well. Here is a logistic regression example with two features X1 and x2. One thing we could do, is fit logistic regression with just a simple hypothesis like this, where, as usual, G is my sigmoid function. And if you do that, you end up with a hypothesis, trying to use, maybe, just a straight line to separate the positive and the negative examples. And this doesn't look like a very good fit to the hypothesis. So, once again, this is an example of underfitting or of the hypothesis having high bias.</p></div><div class="el-p"><p dir="auto">과적합은 선형 회귀뿐만 아니라 로지스틱 회귀에서도 발생합니다. 여기 피처 x1, x2를 가진 로지스틱 회귀 예제가 있습니다. 왼쪽 그림은 로지스틱 회귀 가설 시그모이드 함수 g(z)는 간단한 1차 함수를 사용한 것입니다. 로지스틱 회귀 가설은 간단한 직선으로 파지티브 클래스와 네거티브 클래스를 나눕니다. <strong>직선은 데이터에 잘 맞지 않습니다. 이것은 과소 적합 (Underfit) 또는 높은 편향 (High Bias)입니다.</strong></p></div><div class="el-p"><p dir="auto">In contrast, if you were to add to your features these quadratic terms, then, you could get a decision boundary that might look more like this. And, you know, that's a pretty good fit to the data. Probably, about as good as we could get, on this training set.</p></div><div class="el-p"><p dir="auto">중간의 그림은 시그모이드 함수 g(z)에 2차 다항식을 추가하여 2차 함수의 그래프 모양의 결정 경계를 만들었습니다. 데이터에 잘 맞습니다. 이 곡선이 학습 데이터 셋에 최적인 것 같습니다.</p></div><div class="el-p"><p dir="auto">And, finally, at the other extreme, if you were to fit a very high-order polynomial, if you were to generate lots of high-order polynomial terms of speeches, then, logistical regression may contort itself, may try really hard to find a decision boundary that fits your training data or go to great lengths to contort itself, to fit every single training example well. And, you know, if the features X1 and X2 offer predicting, maybe, the cancer to the, you know, cancer is a malignant, benign breast tumors. This doesn't, this really doesn't look like a very good hypothesis, for making predictions. And so, once again, this is an instance of overfitting and, of a hypothesis having high variance and not really, and, being unlikely to generalize well to new examples.</p></div><div class="el-p"><p dir="auto">오른쪽 그림은 극단적인 예제입니다. 엄청 많은 고차 다항식으로 구성된 로지스틱 회귀 가설은 데이터에 잘 맞는 자잘 자잘하게 꼬아진 결정 경계를 만듭니다. 학습 데이터 셋의 모든 예제에 적합하기 위해 엄청 길게 꼬여 있습니다. <strong>피처 x1과 x2로 암이 악성인지 아닌지를 판단할 때 정말 좋지 못한 예측을 합니다. 이것은 과적합(Overfit) 또는 높은 분산 (High Variance)입니다.</strong> 가설은 새로운 예제에 제대로 일반화할 수 없습니다.</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.51.05 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/n_sUS_LPbX6Gh83bwK7YyyWjqDM.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">Later, in this course, when we talk about debugging and diagnosing things that can go wrong with learning algorithms, we'll give you specific tools to recognize when overfitting and, also, when underfitting may be occurring. But, for now, lets talk about the problem of, if we think overfitting is occurring, what can we do to address it? In the previous examples, we had one or two dimensional data so, we could just plot the hypothesis and see what was going on and select the appropriate degree polynomial. So, earlier for the housing prices example, we could just plot the hypothesis and, you know, maybe see that it was fitting the sort of very wiggly function that goes all over the place to predict housing prices. And we could then use figures like these to select an appropriate degree polynomial. So plotting the hypothesis, could be one way to try to decide what degree polynomial to use.</p></div><div class="el-p"><p dir="auto">이 과정의 뒷부분에서 학습 알고리즘이 과적합인지 아닌지를 확인하는 디버깅과 분석 툴을 설명할 것입니다. 과소 적합도 다룰 것이지만 여기서는 과적합 문제를 다룹니다. 과적합이 발생하는 지를 어떻게 알 수 있을 까요? 지금까지 예제들은 모두 1차원과 2차원 데이터이므로 간단하게 도식화한 후에 가설의 상태를 파악하고 적당한 차원의 다항식을 선택합니다. 주택 가격을 예측하는 예를 그래프로 그리면 적당히 꼬불꼬불한 선이 학습 데이터 셋을 지나갈 것입니다. 그래프를 보고 적당한 수준의 다항식을 선택합니다. 따라서, <strong>가설을 그래프로 그린 후에 어떤 다항식을 사용하는지 보는 것도 한 가지 방법입니다.</strong></p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.43.47 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/dOmXAvQGkASDDQ0qddhKpe0UmrU.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">But that doesn't always work. And, in fact more often we may have learning problems that where we just have a lot of features. And there is not just a matter of selecting what degree polynomial. And, in fact, when we have so many features, it also becomes much harder to plot the data and it becomes much harder to visualize it, to decide what features to keep or not. So concretely, if we're trying predict housing prices sometimes we can just have a lot of different features. And all of these features seem, you know, maybe they seem kind of useful. But, if we have a lot of features, and, very little training data, then, over fitting can become a problem.</p></div><div class="el-p"><p dir="auto">하지만 이 방법을 항상 사용할 수 없습니다. 다항식의 차수가 높을 때와 피처가 매우 많을 때는 그림으로 표현할 수 없습니다. 피처가 증가할수록 데이터를 시각화하는 것은 더욱 어렵습니다. 어떤 피처를 그래프로 표현할지 선택하는 것은 쉽지 않습니다. 예를 들면, 주택 가격을 예측하기 위한 알고리즘의 피처가 100개입니다. 더욱이 모든 피처를 활용할 것입니다. 지금처럼 <strong>피처는 많지만 학습 데이터셋이 적을 때 과적합 (Overfit)이 발생합니다.</strong></p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.56.05 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/Lt_SCzuxyK3uGpeSCrU5Ss_nfdM.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">In order to address over fitting, there are two main options for things that we can do. The first option is, to try to reduce the number of features. Concretely, one thing we could do is manually look through the list of features, and, use that to try to decide which are the more important features, and, therefore, which are the features we should keep, and, which are the features we should throw out. Later in this course, where also talk about model selection algorithms. Which are algorithms for automatically deciding which features to keep and, which features to throw out. This idea of reducing the number of features can work well, and, can reduce over fitting. And, when we talk about model selection, we'll go into this in much greater depth. But, the disadvantage is that, by throwing away some of the features, is also throwing away some of the information you have about the problem. For example, maybe, all of those features are actually useful for predicting the price of a house, so, maybe, we don't actually want to throw some of our information or throw some of our features away.</p></div><div class="el-p"><p dir="auto">과적합 문제를 해결하는 두 가지 옵션이 있습니다. <strong>첫 번째 옵션은 피처의 개수를 줄이는 것입니다</strong>. 예를 들면, 쓸만한 피처와 쓸모없는 피처를 구분합니다. 무엇을 남기고 무엇을 버릴지를 결정합니다. 이 과정의 후반부에서 모델 선택 알고리즘을 배울 것입니다. 알고리즘이 어떤 피처를 사용할지와 버릴지를 자동으로 결정합니다. 피처의 수를 줄이면 과적합 문제를 해결할 수 있습니다. 모델 선택 알고리즘의 단점은 피처를 버리면서 문제에 포함된 정보까지 같이 버릴 수 있습니다. 예를 들어, 모든 피처들이 주택 가격을 예측하기 위해 필요하다면 버릴 수 없습니다.</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-18 at 12.01.53 AM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/GtE0Eqjv2elIQ7FvLL189CGp0gc.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">The second option, which we'll talk about in the next few videos, is regularization. Here, we're going to keep all the features, but we're going to reduce the magnitude or the values of the parameters theta J. And, this method works well, we'll see, when we have a lot of features, each of which contributes a little bit to predicting the value of Y, like we saw in the housing price prediction example. Where we could have a lot of features, each of which are, you know, somewhat useful, so, maybe, we don't want to throw them away. So, this subscribes the idea of regularization at a very high level. And, I realize that, all of these details probably don't make sense to you yet.</p></div><div class="el-p"><p dir="auto"><strong>두 번째 옵션은 정규화(Regularization)입니다.</strong> 다음 강의에서 다룰 것입니다. 모든 피처를 남기지만, 피처가 주는 영향의 규모를 줄입니다. 즉, 파라미터 θ의 값을 조정하여 영향의 규모를 줄입니다. 엄청 많은 피처가 있을 때 각각의 피처는 예측값에 상대적으로 작은 영향을 미칠 것입니다. 예를 들면, 주택 가격을 예측하는 피처가 있고, 피처가 예측에 영향을 미치기 때문에 제거할 수 없습니다. 정규화(Regularization)가 필요한 순간입니다. 정규화의 큰 그림만 설명하고 자세한 사항은 설명하지 않았습니다.</p></div><div class="el-p"><p dir="auto">But, in the next video, we'll start to formulate exactly how to apply regularization and, exactly what regularization means.And, then we'll start to figure out, how to use this, to make how learning algorithms work well and avoid overfitting.</p></div><div class="el-p"><p dir="auto">그러나 다음 강의에서 수학적으로 정규화의 정의와 정규화를 적용하는 방법을 설명할 것입니다. 그리고 학습 알고리즘이 성능을 개선하고 과적합을 피하기 위해 정규화를 사용하는 법부터 이해할 것입니다.</p></div><div class="el-h3"><h3 data-heading="앤드류 응이 머신 러닝 동영상 강의" dir="auto" class="heading" id="앤드류_응이_머신_러닝_동영상_강의_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>앤드류 응이 머신 러닝 동영상 강의</h3></div><div class="el-h3"><h3 data-heading="정리하며" dir="auto" class="heading" id="정리하며_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>정리하며</h3></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-21 at 11.42.45 AM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/1dYX-tVMRMM_Qyal3X0eGgLa7dI.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">왼쪽 그림의 가설 함수는 1차 함수이고 데이터에 적합한 파란색 직선을 그립니다. 이렇게 학습 데이터 셋에 적합하지 않은 것을 과소 적합(Underfit)이라고 합니다. 또는 알고리즘이 높은 편향성(bias), 강한 선입견(preconception)이 있다고 있습니다.</p></div><div class="el-p"><p dir="auto">가운데 그림의 가설 함수는 2차 함수이고 데이터에 적합한 파란색 곡선을 그립니다. 이건 데이터에 잘 맞는다 (Jist right)라고 합니다.</p></div><div class="el-p"><p dir="auto">오른쪽 그림의 가설 함수는 4차 함수이고 데이터에 완전히 적합한 불규칙 곡선입니다. 다항식을 가진 함수들은 데이터에 완적 적합한 곡선을 그릴 수 있습니다. 직관적으로 곡선이 보기에 좋지 않고 이 선이 주택 가격을 제대로 예측하지 못합니다. 이것을 과적합이라고 합니다. 또는 알고리즘이 높은 분산 (High Variance)를 갖는다고 합니다.</p></div><div class="el-p"><p dir="auto">과적합은 많은 피처들이 있을 때 가설 함수가 학습 데이터 셋에 과적합하여 발생합니다. 학습 데이터 셋에 대한 비용 함수는 거의 0에 가까운 값이나 0이 나오지만 엄청 복잡한 곡선을 그립니다. 따라서, 학습 데이터 셋이 아닌 새로운 예제에 예측을 잘하지 못합니다. 일반화는 가설이 새로운 데이터에 얼마나 잘 맞는 지를 의미합니다.  </p></div><div class="el-p"><p dir="auto">과적합을 해결하는 방법은 몇 가지가 있습니다. 첫 번째 방법은 가설 함수를 그래프로 그려 봅니다. 피처가 개수가 많을수록 시각적으로 표현할 수 없기 때문에 사용이 제한적입니다. 두 번째 방법은 피처의 개수를 줄이는 것입니다. 하지만, 어떤 피처를 제거할지 선택하는 것이 어렵습니다. 따라서 모든 피처를 활용하면서 과적합 문제를 해결하는 방법은 정규화입니다.</p></div><div class="el-h3"><h3 data-heading="문제 풀이" dir="auto" class="heading" id="문제_풀이_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>문제 풀이</h3></div><div class="el-p"><p dir="auto">종양이 양성인지 음성인지를 분류하는 의학 진만 문제가 있습니다. 가설 함수가 훈련용 데이터 셋에 과적 합한다면, 어떤 의미인가요?</p></div><div class="el-p"><p dir="auto"><img alt="Screen Shot 2020-10-17 at 11.30.12 PM.png" src="http://t1.daumcdn.net/brunch/service/user/17Xk/image/nm_pev37Rjt0psynykAtME8HaDM.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"></p></div><div class="el-p"><p dir="auto">정답은 3번입니다.</p></div><div class="el-p"><p dir="auto"><strong>keyword</strong></p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><a data-tooltip-position="top" aria-label="https://brunch.co.kr/keyword/AI" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/keyword/AI" target="_self">AI</a></li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><a data-tooltip-position="top" aria-label="https://brunch.co.kr/keyword/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/keyword/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98" target="_self">알고리즘</a></li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><a data-tooltip-position="top" aria-label="https://brunch.co.kr/keyword/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5" rel="noopener nofollow" class="external-link is-unresolved" href="https://brunch.co.kr/keyword/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5" target="_self">인공지능</a></li>
</ul></div><div class="el-p"><p dir="auto"><em>브런치는 최신 브라우저에 최적화 되어있습니다.</em><a data-tooltip-position="top" aria-label="http://windows.microsoft.com/ko-kr/internet-explorer/download-ie" rel="noopener nofollow" class="external-link is-unresolved" href="http://windows.microsoft.com/ko-kr/internet-explorer/download-ie" target="_self">IE</a> <a data-tooltip-position="top" aria-label="http://www.google.co.kr/chrome/" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.google.co.kr/chrome/" target="_self">chrome</a> <a data-tooltip-position="top" aria-label="http://www.apple.com/kr/safari/" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.apple.com/kr/safari/" target="_self">safari</a></p></div><div class="footer"><div class="data-bar"></div></div></div></div></div><div id="right-content" class="leaf" style="--sidebar-width: var(--sidebar-width-right);"><div id="right-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme-toggle-input" id=""><input class="theme-toggle-input" type="checkbox" id="theme-toggle-input"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="right-sidebar-content" class="leaf-content"><div class="graph-view-wrapper"><div class="feature-header"><div class="feature-title">Interactive Graph</div></div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<div class="graph-icon graph-global" role="button" aria-label="Global Graph" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-git-fork"><circle cx="12" cy="18" r="3"></circle><circle cx="6" cy="6" r="3"></circle><circle cx="18" cy="6" r="3"></circle><path d="M18 9v2c0 .6-.4 1-1 1H7c-.6 0-1-.4-1-1V9"></path><path d="M12 12v3"></path></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div id="outline" class=" tree-container"><div class="feature-header"><div class="feature-title">Table Of Contents</div><button class="clickable-icon nav-action-button tree-collapse-all" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-item mod-collapsible" data-depth="1"><a class="tree-item-self is-clickable mod-collapsible" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#앤드류_응의_머신러닝(7-1)_과적합_문제_0" data-path="#앤드류_응의_머신러닝(7-1)_과적합_문제_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="앤드류 응의 머신러닝(7-1): 과적합 문제">앤드류 응의 머신러닝(7-1): 과적합 문제</div></a><div class="tree-item-children"><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#Regularization_0" data-path="#Regularization_0"><div class="tree-item-inner heading-link" heading-name="Regularization">Regularization</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#정규화_0" data-path="#정규화_0"><div class="tree-item-inner heading-link" heading-name="정규화">정규화</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#Solving_the_Problem_of_Overfitting_0" data-path="#Solving_the_Problem_of_Overfitting_0"><div class="tree-item-inner heading-link" heading-name="Solving the Problem of Overfitting">Solving the Problem of Overfitting</div></a><div class="tree-item-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#(과적합_문제_해결하기)_0" data-path="#(과적합_문제_해결하기)_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="(과적합 문제 해결하기)">(과적합 문제 해결하기)</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#The_Problem_of_Overfitting_(과적합_문제)_0" data-path="#The_Problem_of_Overfitting_(과적합_문제)_0"><div class="tree-item-inner heading-link" heading-name="The Problem of Overfitting (과적합 문제)">The Problem of Overfitting (과적합 문제)</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#앤드류_응이_머신_러닝_동영상_강의_0" data-path="#앤드류_응이_머신_러닝_동영상_강의_0"><div class="tree-item-inner heading-link" heading-name="앤드류 응이 머신 러닝 동영상 강의">앤드류 응이 머신 러닝 동영상 강의</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#정리하며_0" data-path="#정리하며_0"><div class="tree-item-inner heading-link" heading-name="정리하며">정리하며</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="600_tech-stack/machine-learning/앤드류-응의-머신러닝(7-1)-과적합-문제.html#문제_풀이_0" data-path="#문제_풀이_0"><div class="tree-item-inner heading-link" heading-name="문제 풀이">문제 풀이</div></a><div class="tree-item-children"></div></div></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector("#right-sidebar"); rs.classList.toggle("is-collapsed", window.innerWidth < 768); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></div></div></body></html>